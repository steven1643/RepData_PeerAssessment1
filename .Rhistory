library(ggplot2)
library(scales)
setwd("~/Box Sync/Programming/R/src")
url_calories = "http://www.fao.org/fileadmin/templates/ess/documents/food_security_statistics/FoodConsumptionNutrients_en.xls"
download.file(url_calories, method="internal", destfile = "FoodConsumptionNutrients_en.xls", mode = "ab")
calories = read.xlsx(file="FoodConsumptionNutrients_en.xls", startRow = 4, colIndex = c(2,6), colClasses = c("character", "numeric"), sheetName="Dietary Energy Cons. Countries", stringsAsFactors=FALSE)
colnames(calories)=c("Country", "Kcal")
url_population = "http://esa.un.org/unpd/wpp/DVD/Files/1_Excel%20(Standard)/EXCEL_FILES/1_Population/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXES.XLS"
download.file(url_population, method="internal", destfile = "Population.xls", mode = "ab")
population = read.xlsx(file="Population.xls", startRow = 17, colIndex = c(3,71), colClasses = c("character", "numeric"), sheetName="ESTIMATES", stringsAsFactors=FALSE)
colnames(population)=c("Country", "Population")
url_obesity = "http://apps.who.int/gho/athena/data/xmart.csv?target=GHO/NCD_BMI_30A&profile=crosstable&filter=AGEGROUP:*;COUNTRY:*;SEX:*&x-sideaxis=COUNTRY&x-topaxis=GHO;YEAR;AGEGROUP;SEX&x-collapse=true"
obesity = read.csv(file=url_obesity, stringsAsFactors=FALSE)
obesity %>% select(matches("Country|2014.*Both")) -> obesity
colnames(obesity)=c("Country", "Obesity")
obesity %>% filter(Obesity!="No data") -> obesity
obesity %>% mutate(Obesity=as.numeric(substr(Obesity, 1, regexpr(pattern = "[[]", obesity$Obesity)-1))) -> obesity
population %>% inner_join(calories,by = "Country") %>% inner_join(obesity,by = "Country") -> data
opts=theme(
panel.background = element_rect(fill="gray98"),
panel.border = element_rect(colour="black", fill=NA),
axis.line = element_line(size = 0.5, colour = "black"),
axis.ticks = element_line(colour="black"),
panel.grid.major = element_line(colour="gray75", linetype = 2),
panel.grid.minor = element_blank(),
axis.text = element_text(colour="gray25", size=15),
axis.title = element_text(size=18, colour="gray10"),
legend.key = element_blank(),
legend.position = "none",
legend.background = element_blank(),
plot.title = element_text(size = 40, colour="gray10"))
ggplot(data, aes(x=Kcal, y=Obesity/100, size=log(Population), label=Country), guide=FALSE)+
geom_point(colour="white", fill="sandybrown", shape=21, alpha=.55)+
scale_size_continuous(range=c(2,40))+
scale_x_continuous(limits=c(1500,4100))+
scale_y_continuous(labels = percent)+
labs(title="The World We Live In #5: Calories And Kilograms",
x="Dietary Energy Consumption (kcal/person/day)",
y="% population with body mass index >= 30 kg/m2")+
geom_text(data=subset(data, Obesity>35|Kcal>3700), size=5.5, colour="gray25", hjust=0, vjust=0)+
geom_text(data=subset(data, Kcal<2000), size=5.5, colour="gray25", hjust=0, vjust=0)+
geom_text(data=subset(data, Obesity<10 & Kcal>2600), size=5.5, colour="gray25", hjust=0, vjust=0)+
geom_text(aes(3100, .01), colour="gray25", hjust=0,
label="Source: United Nations (size of bubble depending on population)", size=4.5)+opts
ggplot(data, aes(x=Kcal, y=Obesity/100, size=log(Population), label=Country), guide=FALSE) +
geom_point(colour="white", fill="sandybrown", shape=21, alpha=.55) +
scale_size_continuous(range=c(2,40)) +
scale_x_continuous(limits=c(1500,4100)) +
scale_y_continuous(labels = percent) +
labs(title="Calories And Kilograms",
x="Dietary Energy Consumption (kcal/person/day)",
y="% population with body mass index >= 30 kg/m2") +
geom_text(data=subset(data, Obesity>35|Kcal>3700), size=5.5, colour="gray25", hjust=0, vjust=0) +
geom_text(data=subset(data, Kcal<2000), size=5.5, colour="gray25", hjust=0, vjust=0) +
geom_text(data=subset(data, Obesity<10 & Kcal>2600), size=5.5, colour="gray25", hjust=0, vjust=0) +
geom_text(aes(3100, .01), colour="gray25", hjust=0,
label="Source: United Nations (size of bubble depending on population)", size=4.5) + opts
dev.copy(png, file="CaloriesAndKilograms.png", width=480*2*1.5, height=480*2); dev.off()
swirl()
library(swirl)
swirl()
x <- c(1, NA, 2, 3, NA, NA)
is.na(x)
mean(is.na(x))
sum(is.na(x))
swirl()
str(diamonds)
qplot(price, diamonds)
qplot(diamonds$price, diamonds)
qplot(price, data=diamonds)
range(diamond$price)
range(diamonds$price)
qplot(price, data=diamonds, binwidth=18487/30)
qplot(price, data=diamonds, binwidth=18487 / 30)
qplot(price,data=diamonds,binwidth=18497/30)
brk
counts
qplot(price,data=diamonds,binwidth=18497/30, fill=cut)
qplot(price, data=diamonds, geom="density")
qplot(price, data=diamonds, geom="density", color=cut)
qplot(carat, price, data=diamonds)
qplot(carat, price, data=diamonds, shape=cut)
qplot(carat, price, data=diamonds, color=cut)
qplot(carat, price, data=diamonds, color=cut, geom=c("point", "smooth"), method="lm")
qplot(carat, price, data=diamonds, color=cut, geom=c("point", "smooth"), method="lm", facets= =.~cut)
qplot(carat, price, data=diamonds, color=cut, geom=c("point", "smooth"), method="lm", facets=.~cut)
g <- ggplot(diamonds, aes(depth, price))
summary(g)
g + geom_point(alpha=3)
g + geom_point(alpha=1/3)
cutpoints <- quantile(diamonds$carat, seq(0, 1, 4), na.rm=TRUE)
cutpoints <- quantile(diamonds$carat, seq(0, 1, length=4), na.rm=TRUE)
cutpoints
diamonds$car2 <- cutpoints
diamonds$car2 <- cut(diamonds$carat, cutpoint)
diamonds$car2 <- cut(diamonds$carat, cutpoints)
View(diamonds)
g <- ggplot(diamonds, aes(depth, price))
g + geom_point(alpha=1/3) + facet_grid(cut ~ car2)
diamonds[myd, ]
g + geom_point(alpha=1/3) + facet_grid(cut ~ car2) + geom_smooth(method="lm", size=3, color="pink")
ggplot(diamonds, aes(carat, price)) + geom_boxplot() + facet_grid( . ~ cut)
dist(dataframe)
dist(dataFrame)
hc <- hclust(distxy)
plot(hc)
plot(as.dendograma(hc))
plot(as.dendogram(hc))
plot(as.dendrogram(hc))
abline(h=1.5, col="blue")
abline(h=0.4, col="red")
5
12
abline(h=0.05, col="green")
dist(dFsm)
hc
heatmap(dataMatrix, cm.colors(25))
heatmap(dataMatrix, COL=cm.colors(25))
heatmap(dataMatrix, col=cm.colors(25))
heatmap(mt)
mt
plot(disp, hp)
plot(denmt)
distmt
cmat
points(cx, cy, col=c("red", "orange", "purple"), pch=3, cex=2, lwd=2)
mdist(x, y, cx, cy)
apply(distTmp, 2, which.min )
points(x, y, pch=19, cex=2, col=cols1[newClust])
tapply(x, newClust, mean)
tapply(y, newClust, mean)
points(newCx, newCy, col=cols1, pch=8, cex=2)
points(newCx, newCy, col=cols1, pch=8, cex=2, lwd=2)
mdist(x, y, newCx, newCy)
apply(distTmp2, 2, which.min)
points(x, y, pch=19, cex=2, col=cols1[newClust2])
tapply(x, newClust2, mean)
tapply(y, newClust2, mean)
points(finalCx, finalCy, col=cols1, pch=9, cex=2, lwd=2)
kmeans(dataFrame, centers=3)
kmObj$iter
plot(x, y, col=kmObj$cluster, pch=19, cex=2)
points(knObj$centers, col=c("black", "red", "green"), pch=3, cex=3, lwd=3)
points(kmObj$centers, col=c("black", "red", "green"), pch=3, cex=3, lwd=3)
plot(x, y, col=kmeans(dataFrame, 6)$cluster, pch=19, cex=2)
plot(x, y, col=kmeans(dataFrame, 6)$cluster, pch=19, cex=2)
plot(x, y, col=kmeans(dataFrame, 6)$cluster, pch=19, cex=2)
install.packages("tm")
install.packages("SnoballC")
install.packages(c("Cairo", "class", "curl", "foreign", "hexbin", "httpuv", "manipulate", "maps", "MASS", "mgcv", "nlme", "nnet", "R6", "Rcpp", "rJava", "scales", "shiny", "spatial"))
install.packages("SnowballC")
install.packages("wordcloud")
setwd("C:/Users/steven.aurousseau/Box Sync/Programming/R/src")
setwd("~/Box Sync/Programming/R/src")
jeopQ <- read.csv('C:/Users/steven.aurousseau/Box Sync/Programming/R/data/JEOPARDY_CSV.csv', stringsAsFactors = FALSE)
jeopQ <- read.csv('~/Box Sync/Programming/R/data/JEOPARDY_CSV.csv', stringsAsFactors = FALSE)
jeopCorpus <- Corpus(VectorSource(jeopQ$Question))
library(tm)
library(SnowballC)
library(wordcloud)
jeopCorpus <- Corpus(VectorSource(jeopQ$Question))
head(jeopCorpus)
jeopCorpus <- tm_map(jeopCorpus, PlainTextDocument)
head(jeopCorpus)
jeopCorpus <- tm_map(jeopCorpus, removePunctuation)
jeopCorpus <- tm_map(jeopCorpus, removeWords, c('the', 'this', stopwords('english')))
jeopCorpus <- tm_map(jeopCorpus, stemDocument)
wordcloud(jeopCorpus, max.words=100, random.order=FALSE)
rm(jeopCorpus)
jeopCorpus <- Corpus(VectorSource(jeopQ$Question))
# next convert the corpus to a plain text document.
jeopCorpus <- tm_map(jeopCorpus, PlainTextDocument)
# remove all punctuation and stopwords
jeopCorpus <- tm_map(jeopCorpus, removePunctuation)
jeopCorpus <- tm_map(jeopCorpus, removeWords, stopwords('english'))
jeopCorpus <- tm_map(jeopCorpus, removeWords, c("the", "this"))
#jeopCorpus <- tm_map(jeopCorpus, removeWords, c('the', 'this', stopwords('english')))
#  words are converted to their stem (Ex: learning -> learn, walked -> walk, etc.)
jeopCorpus <- tm_map(jeopCorpus, stemDocument)
# plot the wordcloud.
wordcloud(jeopCorpus, max.words=100, random.order=FALSE)
jeopCorpus <- Corpus(VectorSource(jeopQ$Question))
jeopCorpus <- tm_map(jeopCorpus, PlainTextDocument)
# remove all punctuation and stopwords
jeopCorpus <- tm_map(jeopCorpus, removePunctuation)
jeopCorpus <- tm_map(jeopCorpus, removeWords, stopwords('english'))
#jeopCorpus <- tm_map(jeopCorpus, removeWords, c('the', 'this', stopwords('english')))
jeopCorpus <- tm_map(jeopCorpus, removeWords("the", "this", stopwords("english")))
jeopCorpus <- Corpus(VectorSource(jeopQ$Question))
# next convert the corpus to a plain text document.
jeopCorpus <- tm_map(jeopCorpus, PlainTextDocument)
# remove all punctuation and stopwords
jeopCorpus <- tm_map(jeopCorpus, removePunctuation)
jeopCorpus <- tm_map(jeopCorpus, removeWords, stopwords('english'))
#jeopCorpus <- tm_map(jeopCorpus, removeWords, c('the', 'this', stopwords('english')))
#jeopCorpus <- tm_map(jeopCorpus, removeWords("the", "this", stopwords("english")))
#  words are converted to their stem (Ex: learning -> learn, walked -> walk, etc.)
jeopCorpus <- tm_map(jeopCorpus, stemDocument)
# plot the wordcloud.
wordcloud(jeopCorpus, max.words=100, random.order=FALSE)
jeopCorpus <- tm_map(jeopCorpus, removeWords, "the")
wordcloud(jeopCorpus, max.words=100, random.order=FALSE)
setwd("~/Box Sync/Programming/R/src")
lords <- Corpus("lords.txt")
inspect(lords)
lords <- Corpus(DirSource("lords/"))
inpspect(lords)
inspect(lords)
lords <- tm_map(lords, stripWhitespace)
lords <- tm_map(lords, tolower)
lords <- tm_map(lords, removeWords, stopwords(“english”))
lords <- tm_map(lords, removeWords, stopwords("english"))
lords <- tm_map(lords, stemDocument)
wordcloud(lords, scale=c(5,0.5), max.words=100,
random.order=FALSE, rot.per=0.35, use.r.layout=FALSE,
colors=brewer.pal(8, “Dark2”))
wordcloud(lords, scale=c(5,0.5), max.words=100,
random.order=FALSE, rot.per=0.35, use.r.layout=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(lords, scale=c(5,0.5), max.words=100,
random.order=FALSE, rot.per=0.35, use.r.layout=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(lords, scale=c(5,0.5), max.words=100,
random.order=FALSE, rot.per=0.35, use.r.layout=FALSE) # ,
wordcloud(lords, max.words=100, random.order=FALSE)
lords <- Corpus(DirSource("lords/"))
inspect(lords)
lords <- tm_map(lords, stripWhitespace)
lords <- tm_map(lords, tolower)
lords <- tm_map(lords, removeWords, stopwords("english"))
lords <- tm_map(lords, stemDocument)
wordcloud(lords, max.words=100, random.order=FALSE)
lords <- Corpus(DirSource("lords/"))
inspect(lords)
lords <- tm_map(lords, stripWhitespace)
lords <- tm_map(lords, tolower)
lords <- tm_map(lords, removeWords, stopwords("english"))
lords <- tm_map(lords, stemDocument)
wordcloud(lords, max.words=100, random.order=FALSE)
getwd()
inspect(lords)
lords <- tm_map(lords, stripWhitespace)
lords <- tm_map(lords, tolower)
lords <- tm_map(lords, removeWords, stopwords("english"))
lords <- tm_map(lords, stemDocument)
wordcloud(lords, max.words=100, random.order=FALSE)
wordcloud(lords, scale=c(5,0.5), max.words=100,
random.order=FALSE, rot.per=0.35, use.r.layout=FALSE,
colors=brewer.pal(8, "Dark2"))
lords <- Corpus(DirSource("lords/"))
inspect(lords)
inspect(lords)
lords
lords <- tm_map(lords, stripWhitespace)
lords <- tm_map(lords, tolower)
lords <- tm_map(lords, removeWords, stopwords("english"))
lords <- tm_map(lords, stemDocument)
wordcloud(lords, scale=c(5,0.5), max.words=100,
random.order=FALSE, rot.per=0.35, use.r.layout=FALSE,
colors=brewer.pal(8, "Dark2"))
inspect(lords)
installed.packages("RColorBrewer")
installed.packages("RColorBrewer")
install.packages("RColorBrewer")
install.packages("RColorBrewer")
getwd()
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
text <- readLines(filePath)
head(text)
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
rm(filePath, text, toSpace)
library("RColorBrewer")
et.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
#  plot
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
text <- readLines("vision.txt")
text
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
rm(filePath, text, toSpace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
text <- readLines(filePath)
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
#  replace "/", "@", "|" with space
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
rm(filePath, text, toSpace)
#  tidy
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
# build a term doc
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
#  plot
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
text <- readLines("gary.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
#  replace "/", "@", "|" with space
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
rm(filePath, text, toSpace)
#  tidy
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)
# build a term doc
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
#  plot
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
text <- readLines("gary.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
#  replace "/", "@", "|" with space
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
rm(filePath, text, toSpace)
#  tidy
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
# Text stemming
#docs <- tm_map(docs, stemDocument)
# build a term doc
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
#  plot
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
dev.copy(png, file="gary.png", width=480*2, height=480*2); dev.off()
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=50, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=80, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
dev.copy(png, file="gary.png", width=480*2, height=480*2); dev.off()
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=80, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
dev.copy(png, file="gary.png", width=480, height=480); dev.off()
text <- readLines("gary.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
#  replace "/", "@", "|" with space
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
rm(filePath, text, toSpace)
#  tidy
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("cat", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
# Text stemming
#docs <- tm_map(docs, stemDocument)
# build a term doc
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
#  plot
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=80, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
dev.copy(png, file="gary.png", width=480, height=480); dev.off()
c(63, 66, 56, 57) / 4
(63 + 66+ 56+ 57) / 4
setwd("C:/Users/steven.aurousseau/Box Sync/Programming/Coursera - Data Science/5.0 Reproducible Research/RepData_PeerAssessment1")
setwd("C:/Users/steven.aurousseau/Box Sync/Programming/Coursera - Data Science/5.0 Reproducible Research/RepData_PeerAssessment1")
setwd("~/Box Sync/Programming/Coursera - Data Science/5.0 Reproducible Research/RepData_PeerAssessment1")
data <- read.csv("activity.csv")
library(tidyr)
avg.steps.per.interval <- aggregate(steps ~ interval, data=data, mean, na.rm=TRUE)  # intervals 0-288 with avg. steps
data %>% replace_na(steps = avg.steps.per.interval$steps) <- data  # not working
data %>% replace_na(list(steps = avg.steps.per.interval$steps))  # not working
library(tidyr)
data %>% replace_na(list(steps = avg.steps.per.interval$steps))  # not working
install.packages(c("dplyr", "jsonlite", "lpSolve", "manipulate", "mime", "Rcpp", "tidyr"))
library(tidyr)
data %>% replace_na(list(steps = avg.steps.per.interval$steps))  # not working
data <- data %>% replace_na(list(steps = avg.steps.per.interval$steps))  # not working
View(data)
is.na(data)
sum(is.na(data))
mean(data)
mean(data$steps)
summary(data)
ds2  <- data[!complete.cases(data) == TRUE, ]  # df of 2304 NA's
ds2[, 1] <- avg.steps.per.interval$steps  # loops thru filling
rm(data)
rm(ds2)
data <- read.csv("activity.csv")
avg.steps.per.interval <- aggregate(steps ~ interval, data=data, mean, na.rm=TRUE)  # intervals 0-288 w/ abg steps
ds2  <- data[!complete.cases(data) == TRUE, ]  # df of 2304 NA's
ds2[, 1] <- avg.steps.per.interval$steps  # loops thru filling
data.filled <- rbind(data[complete.cases(data), ], ds2)
mean(data.filled$steps)
data.tidyr <- data %>% replace_na(list(steps = avg.steps.per.interval$steps))  # not working
mean(data.tidyr)
data.tidyr <- data %>% replace_na(list(steps = avg.steps.per.interval$steps))
mean(data.tidyr$steps)
summary(data.tidyr$steps)
summary(data.filled$steps)
